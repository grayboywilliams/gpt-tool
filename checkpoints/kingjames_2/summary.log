2023-11-29 22:01:26,355 - Model training in progress...
2023-11-29 22:01:26,357 - num_batch: 10000, eval_interval: 100, eval_size: 50
2023-11-29 22:03:36,379 - step 0: train loss 4.4907, val loss 4.4913, time 00:02:10
2023-11-29 22:09:15,522 - step 100: train loss 2.4051, val loss 2.4160, time 00:07:49
2023-11-29 22:14:52,228 - step 200: train loss 2.2969, val loss 2.3164, time 00:13:25
2023-11-29 22:20:30,385 - step 300: train loss 2.1999, val loss 2.2232, time 00:19:04
2023-11-29 22:26:01,574 - step 400: train loss 1.9536, val loss 1.9964, time 00:24:35
2023-11-29 22:31:36,148 - step 500: train loss 1.7464, val loss 1.8293, time 00:30:09
2023-11-29 22:37:06,566 - step 600: train loss 1.6015, val loss 1.6932, time 00:35:40
2023-11-29 22:42:42,324 - step 700: train loss 1.5098, val loss 1.6152, time 00:41:15
2023-11-29 22:48:14,683 - step 800: train loss 1.4361, val loss 1.5558, time 00:46:48
2023-11-29 22:53:47,470 - step 900: train loss 1.3835, val loss 1.5033, time 00:52:21
2023-11-29 22:59:21,405 - step 1000: train loss 1.3426, val loss 1.4726, time 00:57:55
2023-11-29 23:05:00,451 - step 1100: train loss 1.3149, val loss 1.4516, time 01:03:34
2023-11-29 23:10:36,957 - step 1200: train loss 1.2951, val loss 1.4223, time 01:09:10
2023-11-29 23:16:13,221 - step 1300: train loss 1.2668, val loss 1.4050, time 01:14:46
2023-11-29 23:21:50,153 - step 1400: train loss 1.2468, val loss 1.3949, time 01:20:23
2023-11-29 23:27:24,094 - step 1500: train loss 1.2424, val loss 1.3903, time 01:25:57
2023-11-29 23:33:04,164 - step 1600: train loss 1.2242, val loss 1.3658, time 01:31:37
2023-11-29 23:38:39,413 - step 1700: train loss 1.2056, val loss 1.3619, time 01:37:13
2023-11-29 23:44:13,793 - step 1800: train loss 1.1983, val loss 1.3458, time 01:42:47
2023-11-29 23:49:49,163 - step 1900: train loss 1.1919, val loss 1.3422, time 01:48:22
2023-11-29 23:55:24,058 - step 2000: train loss 1.1873, val loss 1.3455, time 01:53:57
2023-11-30 00:01:05,236 - step 2100: train loss 1.1755, val loss 1.3312, time 01:59:38
2023-11-30 00:06:43,856 - step 2200: train loss 1.1672, val loss 1.3242, time 02:05:17
2023-11-30 00:12:34,494 - step 2300: train loss 1.1557, val loss 1.3170, time 02:11:08
2023-11-30 00:18:09,506 - step 2400: train loss 1.1537, val loss 1.3122, time 02:16:43
2023-11-30 00:23:43,636 - step 2500: train loss 1.1434, val loss 1.3043, time 02:22:17
2023-11-30 00:29:27,838 - step 2600: train loss 1.1439, val loss 1.3031, time 02:28:01
2023-11-30 00:35:02,419 - step 2700: train loss 1.1350, val loss 1.2956, time 02:33:36
2023-11-30 00:40:37,911 - step 2800: train loss 1.1349, val loss 1.2958, time 02:39:11
2023-11-30 00:46:14,157 - step 2900: train loss 1.1296, val loss 1.2943, time 02:44:47
2023-11-30 00:51:56,976 - step 3000: train loss 1.1196, val loss 1.2788, time 02:50:30
2023-11-30 00:57:32,395 - step 3100: train loss 1.1233, val loss 1.2806, time 02:56:06
2023-11-30 01:03:13,677 - step 3200: train loss 1.1102, val loss 1.2693, time 03:01:47
2023-11-30 01:08:46,300 - step 3300: train loss 1.1079, val loss 1.2720, time 03:07:19
2023-11-30 01:14:17,974 - step 3400: train loss 1.1022, val loss 1.2658, time 03:12:51
2023-11-30 01:20:08,794 - step 3500: train loss 1.1038, val loss 1.2680, time 03:18:42
2023-11-30 01:25:39,890 - step 3600: train loss 1.0968, val loss 1.2591, time 03:24:13
2023-11-30 01:31:13,916 - step 3700: train loss 1.0959, val loss 1.2494, time 03:29:47
2023-11-30 01:36:50,201 - step 3800: train loss 1.0872, val loss 1.2421, time 03:35:23
2023-11-30 01:42:25,182 - step 3900: train loss 1.0810, val loss 1.2349, time 03:40:58
2023-11-30 01:47:57,157 - step 4000: train loss 1.0806, val loss 1.2304, time 03:46:30
2023-11-30 01:53:33,011 - step 4100: train loss 1.0804, val loss 1.2326, time 03:52:06
2023-11-30 01:59:11,312 - step 4200: train loss 1.0713, val loss 1.2326, time 03:57:44
2023-11-30 02:04:47,217 - step 4300: train loss 1.0747, val loss 1.2314, time 04:03:20
2023-11-30 02:10:21,834 - step 4400: train loss 1.0666, val loss 1.2275, time 04:08:55
2023-11-30 02:15:58,158 - step 4500: train loss 1.0623, val loss 1.2319, time 04:14:31
2023-11-30 02:21:33,491 - step 4600: train loss 1.0622, val loss 1.2249, time 04:20:07
2023-11-30 02:27:07,959 - step 4700: train loss 1.0634, val loss 1.2309, time 04:25:41
2023-11-30 02:32:43,194 - step 4800: train loss 1.0595, val loss 1.2254, time 04:31:16
2023-11-30 02:38:19,606 - step 4900: train loss 1.0574, val loss 1.2186, time 04:36:53
2023-11-30 02:43:55,275 - step 5000: train loss 1.0578, val loss 1.2231, time 04:42:28
2023-11-30 02:49:29,734 - step 5100: train loss 1.0552, val loss 1.2162, time 04:48:03
2023-11-30 02:55:05,959 - step 5200: train loss 1.0498, val loss 1.2156, time 04:53:39
2023-11-30 03:00:38,291 - step 5300: train loss 1.0556, val loss 1.2161, time 04:59:11
2023-11-30 03:06:14,089 - step 5400: train loss 1.0425, val loss 1.2133, time 05:04:47
2023-11-30 03:11:49,012 - step 5500: train loss 1.0487, val loss 1.2112, time 05:10:22
2023-11-30 03:17:27,125 - step 5600: train loss 1.0432, val loss 1.2110, time 05:16:00
2023-11-30 03:22:58,771 - step 5700: train loss 1.0404, val loss 1.2119, time 05:21:32
2023-11-30 03:28:34,593 - step 5800: train loss 1.0452, val loss 1.2051, time 05:27:08
2023-11-30 03:34:10,977 - step 5900: train loss 1.0449, val loss 1.2113, time 05:32:44
2023-11-30 03:39:51,134 - step 6000: train loss 1.0395, val loss 1.2061, time 05:38:24
2023-11-30 03:45:39,394 - step 6100: train loss 1.0403, val loss 1.2056, time 05:44:13
2023-11-30 03:51:11,352 - step 6200: train loss 1.0343, val loss 1.2030, time 05:49:44
2023-11-30 03:56:41,210 - step 6300: train loss 1.0359, val loss 1.2006, time 05:55:14
2023-11-30 04:02:19,991 - step 6400: train loss 1.0348, val loss 1.2044, time 06:00:53
2023-11-30 04:07:56,145 - step 6500: train loss 1.0332, val loss 1.1993, time 06:06:29
2023-11-30 04:13:32,732 - step 6600: train loss 1.0303, val loss 1.1958, time 06:12:06
2023-11-30 04:19:09,382 - step 6700: train loss 1.0293, val loss 1.1966, time 06:17:43
2023-11-30 04:24:45,043 - step 6800: train loss 1.0312, val loss 1.1955, time 06:23:18
2023-11-30 04:30:24,177 - step 6900: train loss 1.0315, val loss 1.2037, time 06:28:57
2023-11-30 04:35:59,995 - step 7000: train loss 1.0274, val loss 1.1977, time 06:34:33
2023-11-30 04:41:38,195 - step 7100: train loss 1.0276, val loss 1.1938, time 06:40:11
2023-11-30 04:47:13,348 - step 7200: train loss 1.0251, val loss 1.1934, time 06:45:46
2023-11-30 04:52:52,677 - step 7300: train loss 1.0262, val loss 1.1913, time 06:51:26
2023-11-30 04:58:28,935 - step 7400: train loss 1.0230, val loss 1.1891, time 06:57:02
2023-11-30 05:04:04,217 - step 7500: train loss 1.0181, val loss 1.1873, time 07:02:37
2023-11-30 05:09:35,906 - step 7600: train loss 1.0180, val loss 1.1829, time 07:08:09
2023-11-30 05:15:11,730 - step 7700: train loss 1.0247, val loss 1.1961, time 07:13:45
2023-11-30 05:20:48,539 - step 7800: train loss 1.0138, val loss 1.1891, time 07:19:22
2023-11-30 05:26:22,021 - step 7900: train loss 1.0142, val loss 1.1847, time 07:24:55
2023-11-30 05:31:59,903 - step 8000: train loss 1.0132, val loss 1.1810, time 07:30:33
2023-11-30 05:37:33,856 - step 8100: train loss 1.0084, val loss 1.1791, time 07:36:07
2023-11-30 05:43:10,189 - step 8200: train loss 1.0141, val loss 1.1854, time 07:41:43
2023-11-30 05:48:45,315 - step 8300: train loss 1.0170, val loss 1.1870, time 07:47:18
2023-11-30 05:54:21,068 - step 8400: train loss 1.0096, val loss 1.1810, time 07:52:54
2023-11-30 06:00:01,346 - step 8500: train loss 1.0098, val loss 1.1813, time 07:58:34
2023-11-30 06:05:41,997 - step 8600: train loss 1.0108, val loss 1.1749, time 08:04:15
2023-11-30 06:11:16,264 - step 8700: train loss 1.0090, val loss 1.1838, time 08:09:49
2023-11-30 06:16:56,500 - step 8800: train loss 1.0135, val loss 1.1783, time 08:15:30
2023-11-30 06:22:31,988 - step 8900: train loss 1.0089, val loss 1.1804, time 08:21:05
2023-11-30 06:28:06,470 - step 9000: train loss 1.0103, val loss 1.1836, time 08:26:40
2023-11-30 06:33:43,416 - step 9100: train loss 1.0081, val loss 1.1797, time 08:32:17
2023-11-30 06:39:20,080 - step 9200: train loss 1.0084, val loss 1.1807, time 08:37:53
2023-11-30 06:44:55,969 - step 9300: train loss 1.0074, val loss 1.1779, time 08:43:29
2023-11-30 06:50:29,976 - step 9400: train loss 1.0112, val loss 1.1831, time 08:49:03
2023-11-30 06:56:03,559 - step 9500: train loss 1.0082, val loss 1.1794, time 08:54:37
2023-11-30 07:01:41,321 - step 9600: train loss 1.0023, val loss 1.1731, time 09:00:14
2023-11-30 07:07:15,908 - step 9700: train loss 1.0010, val loss 1.1729, time 09:05:49
2023-11-30 07:12:52,806 - step 9800: train loss 0.9988, val loss 1.1697, time 09:11:26
2023-11-30 07:18:30,397 - step 9900: train loss 1.0042, val loss 1.1712, time 09:17:04
2023-11-30 07:24:01,371 - step 9999: train loss 1.0032, val loss 1.1715, time 09:22:35
2023-11-30 07:26:04,979 - final: test loss 1.3650
2023-11-30 07:26:04,980 - tokens observed: 163840000
2023-11-30 07:26:04,980 - tokens predicted: 640000
2023-11-30 07:26:04,980 - effective epochs: 36.80
2023-11-30 07:26:04,981 - Model training complete.
