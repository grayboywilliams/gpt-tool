2023-11-29 21:44:25,605 - Model training in progress...
2023-11-29 21:44:25,606 - num_batch: 5000, eval_interval: 100, eval_size: 50
2023-11-29 21:44:28,652 - step 0: train loss 4.4970, val loss 4.4967, time 00:00:03
2023-11-29 21:44:39,292 - step 100: train loss 2.7690, val loss 2.7755, time 00:00:13
2023-11-29 21:44:49,987 - step 200: train loss 2.4138, val loss 2.4208, time 00:00:24
2023-11-29 21:45:00,519 - step 300: train loss 2.2941, val loss 2.3084, time 00:00:34
2023-11-29 21:45:10,762 - step 400: train loss 2.2012, val loss 2.2289, time 00:00:45
2023-11-29 21:45:21,100 - step 500: train loss 2.1341, val loss 2.1708, time 00:00:55
2023-11-29 21:45:31,490 - step 600: train loss 2.0681, val loss 2.1133, time 00:01:05
2023-11-29 21:45:41,883 - step 700: train loss 2.0207, val loss 2.0342, time 00:01:16
2023-11-29 21:45:52,558 - step 800: train loss 1.9627, val loss 1.9922, time 00:01:26
2023-11-29 21:46:02,819 - step 900: train loss 1.9091, val loss 1.9558, time 00:01:37
2023-11-29 21:46:13,009 - step 1000: train loss 1.8659, val loss 1.9194, time 00:01:47
2023-11-29 21:46:23,418 - step 1100: train loss 1.8316, val loss 1.8790, time 00:01:57
2023-11-29 21:46:33,679 - step 1200: train loss 1.7930, val loss 1.8470, time 00:02:08
2023-11-29 21:46:44,254 - step 1300: train loss 1.7768, val loss 1.8245, time 00:02:18
2023-11-29 21:46:54,962 - step 1400: train loss 1.7552, val loss 1.8059, time 00:02:29
2023-11-29 21:47:05,281 - step 1500: train loss 1.7475, val loss 1.8100, time 00:02:39
2023-11-29 21:47:15,486 - step 1600: train loss 1.7476, val loss 1.7910, time 00:02:49
2023-11-29 21:47:25,753 - step 1700: train loss 1.7119, val loss 1.7799, time 00:03:00
2023-11-29 21:47:35,960 - step 1800: train loss 1.6926, val loss 1.7554, time 00:03:10
2023-11-29 21:47:46,211 - step 1900: train loss 1.6963, val loss 1.7550, time 00:03:20
2023-11-29 21:47:57,086 - step 2000: train loss 1.6739, val loss 1.7510, time 00:03:31
2023-11-29 21:48:07,588 - step 2100: train loss 1.6553, val loss 1.7284, time 00:03:41
2023-11-29 21:48:17,787 - step 2200: train loss 1.6665, val loss 1.7265, time 00:03:52
2023-11-29 21:48:28,116 - step 2300: train loss 1.6261, val loss 1.7047, time 00:04:02
2023-11-29 21:48:38,430 - step 2400: train loss 1.6341, val loss 1.7160, time 00:04:12
2023-11-29 21:48:49,026 - step 2500: train loss 1.6311, val loss 1.7108, time 00:04:23
2023-11-29 21:48:59,520 - step 2600: train loss 1.6316, val loss 1.6912, time 00:04:33
2023-11-29 21:49:10,084 - step 2700: train loss 1.6143, val loss 1.7115, time 00:04:44
2023-11-29 21:49:20,406 - step 2800: train loss 1.6163, val loss 1.6897, time 00:04:54
2023-11-29 21:49:30,724 - step 2900: train loss 1.6010, val loss 1.6747, time 00:05:05
2023-11-29 21:49:41,430 - step 3000: train loss 1.5843, val loss 1.6805, time 00:05:15
2023-11-29 21:49:51,965 - step 3100: train loss 1.6008, val loss 1.6828, time 00:05:26
2023-11-29 21:50:02,524 - step 3200: train loss 1.5743, val loss 1.6655, time 00:05:36
2023-11-29 21:50:13,170 - step 3300: train loss 1.5878, val loss 1.6707, time 00:05:47
2023-11-29 21:50:23,759 - step 3400: train loss 1.5961, val loss 1.6665, time 00:05:58
2023-11-29 21:50:33,963 - step 3500: train loss 1.5827, val loss 1.6610, time 00:06:08
2023-11-29 21:50:44,356 - step 3600: train loss 1.5606, val loss 1.6471, time 00:06:18
2023-11-29 21:50:54,514 - step 3700: train loss 1.5790, val loss 1.6520, time 00:06:28
2023-11-29 21:51:04,630 - step 3800: train loss 1.5772, val loss 1.6341, time 00:06:39
2023-11-29 21:51:15,316 - step 3900: train loss 1.5508, val loss 1.6477, time 00:06:49
2023-11-29 21:51:25,625 - step 4000: train loss 1.5537, val loss 1.6286, time 00:07:00
2023-11-29 21:51:35,901 - step 4100: train loss 1.5720, val loss 1.6331, time 00:07:10
2023-11-29 21:51:46,405 - step 4200: train loss 1.5594, val loss 1.6454, time 00:07:20
2023-11-29 21:51:56,807 - step 4300: train loss 1.5452, val loss 1.6345, time 00:07:31
2023-11-29 21:52:06,912 - step 4400: train loss 1.5511, val loss 1.6301, time 00:07:41
2023-11-29 21:52:17,732 - step 4500: train loss 1.5395, val loss 1.6374, time 00:07:52
2023-11-29 21:52:27,980 - step 4600: train loss 1.5372, val loss 1.6303, time 00:08:02
2023-11-29 21:52:38,076 - step 4700: train loss 1.5425, val loss 1.6313, time 00:08:12
2023-11-29 21:52:48,319 - step 4800: train loss 1.5361, val loss 1.6231, time 00:08:22
2023-11-29 21:52:58,559 - step 4900: train loss 1.5286, val loss 1.6345, time 00:08:32
2023-11-29 21:53:08,747 - step 4999: train loss 1.5308, val loss 1.5971, time 00:08:43
2023-11-29 21:53:11,815 - final: test loss 1.7779
2023-11-29 21:53:11,816 - tokens observed: 5120000
2023-11-29 21:53:11,816 - tokens predicted: 160000
2023-11-29 21:53:11,816 - effective epochs: 1.15
2023-11-29 21:53:11,817 - Model training complete.
